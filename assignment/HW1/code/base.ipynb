{"cells": [{"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import numpy as np\n", "import pandas as pd\n", "import matplotlib.pyplot as plt"]}, {"cell_type": "markdown", "metadata": {}, "source": ["\n<br>\n", "\ubcf4\uc2a4\ud134 \uc9d1\uac12\uc744 \uc120\ud615\ud68c\uadc0\ud558\uc5ec \uc608\uce21\ud558\ub294 \ucf54\ub4dc\ub97c \uc9dc\uc11c \uc5c5\ub85c\ub4dc \ud558\uc138\uc694.<br>\n", "\uc120\ud615 \ud68c\uadc0\uc5d0\uc11c \ubaa8\uc218\ub97c \ucc3e\ub294 \ubc29\uc2dd\uc740 \ubc18\ub4dc\uc2dc SGD\ub97c \ud65c\uc6a9\ud574\uc57c \ud569\ub2c8\ub2e4.<br>\n", "\ud30c\uc77c\uc740 \ub178\ud2b8\ubd81 \ud30c\uc77c \ud615\uc2dd ipynb\ub85c \uc62c\ub9ac\uae30 \ubc14\ub78d\ub2c8\ub2e4. \ud30c\uc77c\uc740 \ub530\ub85c \ucca8\ubd80\ud560\uac8c\uc694.<br>\n", "training set\uacfc test set\uc744 7:3\uc73c\ub85c \ub098\ub204\uace0 test set\uc5d0 \ub300\ud574 R^2\uac00 \uc5bc\ub9c8\ub098 \ub098\uc624\ub294\uc9c0 \uccb4\ud06c\ud574\uc11c ipynb \ud30c\uc77c\uc5d0 \uc801\uc5b4\ub450\uae30 \ubc14\ub78d\ub2c8\ub2e4.<br>\n", "\ub370\uc774\ud130\uac00 506\uac1c\uc774\ub2c8 \uc55e\uc758 350\uac1c\ub97c training set, \ub4a4\uc758 156\uac1c\ub97c test set\uc73c\ub85c \ud65c\uc6a9\ud558\uba74 \ub420 \uac83 \uac19\ub124\uc694.<br>\n", "--> \uacfc\uc81c \uc218\uc815\ub418\uc5b4 train, test \uc8fc\uc5b4\uc9d0<br>\n", "* NumPy, Matplotlib \ub4f1 \uae30\ubcf8\uc801 \ud328\ud0a4\uc9c0\ub9cc \uc0ac\uc6a9\ud558\uace0, Scikit-Learn \ub4f1 \uc120\ud615 \ud68c\uadc0\uac00 \uad6c\ud604\uc774 \ub418\uc5b4\uc838\uc788\ub294 \ud328\ud0a4\uc9c0\ub294 \uc751\uc6a9 \ud328\ud0a4\uc9c0\ub294 \uc0ac\uc6a9\ud558\uc9c0 \ub9c8\uc138\uc694.<br>\n", "2021313075 \ubc31\uacbd\uc778<br>\n", "R^2 score on test set:  0.712776971324815<br>\n", "Plan<br>\n", "1. SGD\uc640 minibatch-SGD \ube44\uad50\ud558\uae30<br>\n", "2. Hyperparameter \ub2e4\uc591\ud558\uac8c \uc124\uc815\ud558\uae30<br>\n", "Caution<br>\n", "1. Drop nan data<br>\n", "2. Feature scaling<br>\n", ""]}, {"cell_type": "markdown", "metadata": {}, "source": ["Load the dataset"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["train_data = pd.read_csv('./assignment/HW1/data/housing_train.csv')\n", "test_data = pd.read_csv('./assignment/HW1/data/housing_test.csv')"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Drop nan data"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["train_data.dropna(inplace=True)\n", "test_data.dropna(inplace=True)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Separate features and target variable"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["X_train = train_data.drop(columns='MEDV').values\n", "y_train = train_data['MEDV'].values\n", "X_test = test_data.drop(columns='MEDV').values\n", "y_test = test_data['MEDV'].values"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Standardize features (feature scaling)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["X_train_mean = np.mean(X_train, axis=0)\n", "X_train_std = np.std(X_train, axis=0)\n", "X_train = (X_train - X_train_mean) / X_train_std"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["X_test = (X_test - X_train_mean) / X_train_std"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Add intercept term (bias) to features"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["X_train = np.c_[np.ones(X_train.shape[0]), X_train]\n", "X_test = np.c_[np.ones(X_test.shape[0]), X_test]"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Implementing SGD for Linear Regression"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def sgd_linear_regression(X, y, learning_rate=0.001, epochs=512):\n", "    np.random.seed(42)\n", "    m, n = X.shape\n", "    theta = np.random.randn(n)  # Initialize parameters randomly\n", "    for epoch in range(epochs):\n", "        for i in range(m):\n", "            random_index = np.random.randint(m)\n", "            xi = X[random_index:random_index+1]\n", "            yi = y[random_index:random_index+1]\n", "            gradients = xi.T.dot(xi.dot(theta) - yi)\n", "            theta = theta - learning_rate * gradients\n", "    return theta"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Implementing Mini-Batch SGD for Linear Regression"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def mini_batch_sgd_linear_regression(X, y, learning_rate=0.001, epochs=1000, batch_size=32):\n", "    np.random.seed(42)\n", "    m, n = X.shape\n", "    theta = np.random.randn(n)  # Initialize parameters randomly\n", "    for epoch in range(epochs):\n", "        # Shuffle the dataset at the start of each epoch\n", "        shuffled_indices = np.random.permutation(m)\n", "        X_shuffled = X[shuffled_indices]\n", "        y_shuffled = y[shuffled_indices]\n", "        \n", "        # Iterate over mini-batches\n", "        for i in range(0, m, batch_size):\n", "            xi = X_shuffled[i:i + batch_size]\n", "            yi = y_shuffled[i:i + batch_size]\n", "            \n", "            # Compute the gradient for the batch\n", "            gradients = batch_size * xi.T.dot(xi.dot(theta) - yi)\n", "            \n", "            # Update theta\n", "            theta = theta - learning_rate * gradients\n", "    \n", "    return theta"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Train the model"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["theta = sgd_linear_regression(X_train, y_train)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Predict using the model"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["y_pred = X_test.dot(theta)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Calculate R^2 score"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def r_squared(y_true, y_pred):\n", "    ss_res = np.sum((y_true - y_pred) ** 2)\n", "    ss_tot = np.sum((y_true - np.mean(y_true)) ** 2)\n", "    return 1 - (ss_res / ss_tot)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["r2_score = r_squared(y_test, y_pred)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Print R^2 score"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print(\"R^2 score on test set: \", r2_score)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Plot predicted vs actual values"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["plt.figure(figsize=(10, 6))\n", "plt.scatter(y_test, y_pred, color='blue', alpha=0.5)\n", "plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], color='red', lw=2)\n", "plt.xlabel('Actual Prices')\n", "plt.ylabel('Predicted Prices')\n", "plt.title('Actual vs Predicted Prices')\n", "plt.show()"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.4"}}, "nbformat": 4, "nbformat_minor": 2}