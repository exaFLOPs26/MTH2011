## Deep Laerning

Deep Learning is still in a form of GLM.

Goal of AI is efficiency. And unconsciousness might help.
Mathmetical expression of unconsciousness. No need to make complex optimization

- Why use ReLU than sigmoid, tanh?
    - With sigmoid and tanh, we can't discriminate learning for some point.
    - Similar to ReLU as negative signal results the same, we can use leaky ReLU.

Feature mapping is good for non-linear but how?!
We don't know. So just give it to Neural Net and optimize it.

In math, want to find the function. But Neural Net is doing good. Because of stacking. And by stacking NN can find the derived features(variables) by input data.